{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "e4ZG5TtYyJvi",
        "BQOAxQGHLuQN",
        "Q3DVu6dLL1cy",
        "m5vsk0UeMOGd",
        "8m9Szyl2MRAy",
        "5jQC5x5QMc8r",
        "7vkS8p5YNDwp",
        "5l53MwQONL87",
        "GdI662_PNVO1",
        "d4eMBpp5iK2U",
        "NPfd6pUSNriZ",
        "oTsw9gwhNzCn"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorviro/Machine-Learning-Python/blob/master/Monitoring_and_feedback_loop_MLOps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4ZG5TtYyJvi"
      },
      "source": [
        "## Table of contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fkohhru4yJ0M"
      },
      "source": [
        "\n",
        "1. [â„¹ Introduction](#1)\n",
        "2. [âŒ› How often should models be retrained?](#2)\n",
        "3. [ğŸ“‰ Understanding model degradation ](#3)\n",
        "    1. [â†©ï¸ Ground truth evaluation ](#3.1)\n",
        "    2. [â¡ï¸ Input drift detection ](#3.2)\n",
        "5. [ğŸ” The feedback loop ](#5)\n",
        "    1. [âœï¸ Logging](#5.1)\n",
        "    2. [ğŸ“ Model evaluation store](#5.2)\n",
        "    3. [ğŸ†š Online evaluation](#5.3)\n",
        "        1. [ğŸ¥‡ğŸ¥ˆ Champion / Challenger](#5.3.1)\n",
        "        2. [ğŸ…°ğŸ…± A/B testing](#5.3.2)\n",
        "6. [ğŸ““ References](#6)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQOAxQGHLuQN"
      },
      "source": [
        "## â„¹ Introduction <a name=\"1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XR03O7KLymK"
      },
      "source": [
        "There are ğŸ”¢ **multiple reasons to ğŸš§ develop and ğŸš€ deploy a new ML model version**. Sometimes to refine business ğŸ¯ objectives. Other times, the data scientists have come up with new features or a ğŸ‘Œ **better way to design the model**. Another common cause is model **performance ğŸ“‰ degradation**.\n",
        "\n",
        "When an ML model is ğŸš€ deployed in production, its performance can start â¬‡ degrading over time and can impact ğŸ‘ negatively the business. Thatâ€™s why model ğŸ–¥ **monitoring is a ğŸ— crucial step** in the ML model ğŸ”„ lifecycle. ML models need to be **monitored at âœŒ two levels**:\n",
        "\n",
        "| Level   |      â“ Key questions      |\n",
        "|----------|:-------------:|\n",
        "| ğŸ’» **Resource monitoring** |  - Is the **CPU, RAM, network usage, and disk space** as expected? Are requests being processed at the expected rate (**latency**)? |\n",
        "| ğŸ“‰ **Performance monitoring** | Is the model still an **accurate** representation of the pattern of new incoming data, and is it still performing as well as during its design phase? |\n",
        "\n",
        "\n",
        "- <details>\n",
        "  <summary>ğŸ’» <b>Resource monitoring</b></summary>\n",
        "    \n",
        "  It's is the traditional IT performance monitoring. The resource demands of ML models are not so different from traditional software. Overall, the existing expertise in **DevOps** teams **for monitoring and managing resources can be applied to ML models**.\n",
        " </details>\n",
        "\n",
        "- <details>\n",
        "  <summary>ğŸ“‰ <b>Performance monitoring</b></summary>\n",
        "    \n",
        "  It's inherent to ML. **How ğŸ‘ well a model performs** is a â†” reflection of the data used to train it; particularly, **how representative the training data is of the live request data**. As the ğŸŒ world is constantly changing, a static model cannot ğŸ¥… catch up with new patterns that are emerging without a constant source of new data. For example, the training data used to build a fraud detection model six months ago wonâ€™t reflect a new type of fraud that has started to occur in the last three months.\n",
        " </details>\n",
        "\n",
        "\n",
        "<details>\n",
        "  <summary>ğŸ•´ï¸ <b>Business roles</b> also play on monitoring</summary>\n",
        "\n",
        "  Some of their concerns might include â“ questions like: \n",
        "  - Is the model delivering value to the enterprise?\n",
        "  - Do the ğŸ‘ benefits of the model âš–ï¸ outweigh the ğŸ’° cost of developing and ğŸš€ deploying the model? \n",
        "  The **KPIs** identified for the original business ğŸ¯ objective **should be monitored ğŸ¤– automatically** to prove value is â¬† growing.\n",
        "</details>\n",
        "\n",
        "ğŸ“‰ Model performance **monitoring** tracks performance â¬‡ degradation, and at an appropriate time, it can also **trigger the â†©ï¸ retraining** of the model with more representative data. This ğŸ“„ notebook will delve into detail on how data teams should handle both ğŸ–¥ monitoring as well as subsequent â†©ï¸ retraining."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3DVu6dLL1cy"
      },
      "source": [
        "## âŒ› How often should models be retrained? <a name=\"2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNRnLY31L4RE"
      },
      "source": [
        "At some point, model **â†©ï¸ retraining is necessary**. How â³ soon models need to be retrained will depend on many â“ factors:\n",
        "- <details>\n",
        "  <summary>The <b>domain</b>: how âœˆ fast the real ğŸŒ world is changing? </summary>\n",
        "  \n",
        "  - In areas like real-time ğŸ’± trading, models need to be ğŸ”„ updated regularly to keep up with the changes inherent in these fields. \n",
        "  - On the other hand, physical models (like ğŸ—£ voice recognition) are generally more stable, as the patterns donâ€™t often abruptly change over time. \n",
        "</details>\n",
        "\n",
        "\n",
        "- <details>\n",
        "  <summary>Whether the ğŸ’° <b>cost of â†©ï¸ retraining is worth </b> the â¬† improvement in performance</summary>\n",
        "  \n",
        "  For example, if it takes one week to run the whole data pipeline and â†©ï¸ retrain the model, is it worth a 1% of â¬† improvement in performance?\n",
        "</details>\n",
        "\n",
        "\n",
        "- <details>\n",
        "  <summary>A <b>limited ğŸ”¢ number of training examples</b></summary>\n",
        "  \n",
        "  In these cases, the decision to retrain hinges on collecting enough new data\n",
        "</details>\n",
        "\n",
        "  <details>\n",
        "  <summary>There are also two <b>organizational â†•ï¸ bounds</b> to consider about ğŸ”„ retraining frequency</summary>\n",
        "  \n",
        "  - An â†—ï¸ *upper bound*: It's recommended retraining once every year to ensure that the team in charge has the skills to do it and to ensure that the computing âš™ toolchain is still up.\n",
        "\n",
        "  - A â†˜ *lower bound*: Consider a model with âœˆ quick feedback (e.g a recommendation engine). Some performance monitoring techniques (e.g shadow testing or A/B testing) that are used to ğŸ“‰ monitor performance degradation are statistical techniques, so it takes some âŒ› time to gather the required information (at minimum, one day). This necessarily sets a lower bound to the retraining period. The **lag between prediction time and ground truth obtention time** is ğŸ— key to define this â†˜ lower bound. It's âš  risky to use a model when it's likely that it drifts faster than this lag. If the model retraining occurs more often than the lag, there will be almost no impact on the performance of the model. \n",
        "</details>\n",
        "\n",
        "\n",
        "It's âš¡ï¸ critical to know the drift and **accuracy of ğŸš€ deployed models** by setting up âš™ **processes** for ğŸ–¥ **monitoring and ğŸ“§ notifications**. An ideal scenario would be a pipeline that ğŸ¤– automatically triggers âœ… checks for the ğŸ“‰ degradation of model performance. ğŸ“§ Notifications are not necessarily to kick off an automated process of â†©ï¸ retraining, âœ… validation, and ğŸš€ deployment. **Model performance can change due to different reasons, and â†©ï¸ retraining may not always be the answer**. The point is to ğŸ”” alert the data scientist, who can then ğŸ” diagnose the issue and ğŸ¤” evaluate the situation. \n",
        "\n",
        "Practically, every ğŸš€ deployed model should come with monitoring ğŸ“ metrics and corresponding warning ğŸ”¢ thresholds to detect meaningful business performance â¬‡ drops as âœˆ quickly as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5vsk0UeMOGd"
      },
      "source": [
        "## ğŸ“‰ Understanding model degradation <a name=\"3\"></a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHo9ixxFMP_d"
      },
      "source": [
        "**How** can we â— **notice a modelâ€™s performance is â¬‡ degrading?** There are âœŒ **two common approaches**: ground truth evaluation and input drift detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m9Szyl2MRAy"
      },
      "source": [
        "### â†©ï¸ Ground truth evaluation <a name=\"3.1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvnnbLWtMZDW"
      },
      "source": [
        "The **ground truth is the correct answer** to the â“ question the model was asked to solve (e.g. is this credit card transaction actually fraudulent?). \n",
        "\n",
        "<details>\n",
        "  <summary>The âŒ› time that passes between prediction time and ground truth obtention depends on the use case</summary>\n",
        "  \n",
        "  - **Sometimes** ground truth **is obtained ğŸš„ rapidly after a prediction** (e.g. in advertisement recommendation systems, users likely ğŸ–± click on the ads within seconds). \n",
        "\n",
        "  - However, **in many use cases, obtaining the ground truth is much ğŸŒ slower**. For example, a model that predicted that a transaction was not ğŸš« fraudulent, how can this be âœ… confirmed? It'll be reported probably by the cardholder when he reviews their monthly transactions, but this could happen up to a month after the event. In this case, ground truth won't enable monitoring performance accurately on a daily basis. **If the situation requires ğŸ rapid feedback, then input drift detection may be a better approach**. \n",
        "</details>\n",
        "\n",
        "\n",
        "\n",
        "With the new ground truth â†©ï¸ collected, the â¡ next step is to **compute the performance of the model based on ground truth and compare** it with the ğŸ“ metrics. When the difference surpasses a ğŸš threshold, the model can be deemed as outdated, and it should then be ğŸ”„ retrained.\n",
        "\n",
        "The ğŸ“ metrics to be ğŸ“Š monitored can be of âœŒ two varieties:\n",
        "\n",
        "| Type of metric   |      Examples      |  Adventages | Drawbacks |\n",
        "|----------|:-------------:|------:|-----:|\n",
        "| ğŸ”¢ **Statistical metrics**|  Accuracy, ROC AUC... | Domain agnostic. Easy for data scientists to set ğŸš thresholds | Drop may be statistically significant without having any noticeable impact |\n",
        "| ğŸ’¼ **Business metrics** | Cost/benefit assessment | They have a **monetary value** | |\n",
        "\n",
        "\n",
        "> **When available, ground truth monitoring is the â­ best solution**. \n",
        "\n",
        "Ground truth monitoring involves three main âš¡ï¸ **challenges**:\n",
        "\n",
        "- <details>\n",
        "  <summary>â†©ï¸ Ground truth is not always immediately available</summary>\n",
        "  \n",
        "  It can mean significant ğŸ’² economic â¬‡ loss if the model is degrading ğŸš„ quickly.\n",
        "</details>\n",
        "\n",
        "\n",
        "- <details>\n",
        "  <summary>ğŸ”€ Scattered information</summary>\n",
        "  \n",
        "  **To compute the ğŸ“ performance** of the ğŸš€ deployed model on new data, we need ğŸ”— **match ground truth with the corresponding observation**. In many production environments, this is hard because these two pieces of **information** are generated and stored **in different systems** and at different timestamps.\n",
        "</details>\n",
        "\n",
        "\n",
        "- <details>\n",
        "  <summary>ğŸŒ“ Partially available ground truth</summary>\n",
        "  \n",
        "  In some situations, it's ğŸ’µ **expensive to retrieve the ground truth for all the observations**, which means ğŸ‘‰ choosing which **samples** to ğŸ· label and this can inadvertently **introduce bias** into the system. Fraud detection is an example. As transactions need to be examined manually, it seems reasonable to establish ground truth for only suspect cases (cases where the model gives a â¬† high probability of fraud). However, this introduces bias since fraud patterns that were never captured by the model (those that the model predicts a â¬‡ low fraud probability) will be ignored. The ğŸ· labeled sample subset must **cover all the possible future predictions** so that the model continues to generalize ğŸ‘ well.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jQC5x5QMc8r"
      },
      "source": [
        "### â¡ï¸ Input drift detection <a name=\"3.2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-IDHZIFMd1f"
      },
      "source": [
        "> A model will predict ğŸ‘ accurately if the data it was trained on is an accurate â†”ï¸ reflection of the real ğŸŒ world.\n",
        "\n",
        "So if a **comparison** of recent production data ğŸ†š against the training data **shows differences, then it's likely that the model performance is compromised**. The ğŸ¤© beauty of this approach is that all the data required already exists (**no need to ğŸ¤š wait for ground truth**).\n",
        "\n",
        "But, **how can drift be detected?** There are âœŒ two common approaches. \n",
        "\n",
        "- <details>\n",
        "  <summary>ğŸ”¢ Univariate <b>statistical tests</b></summary>\n",
        "  \n",
        "  For each feature, a statistical âœ… test is applied on data from the training data distribution and the production data distribution. A âš ï¸ warning will be raised when the results of those tests are significant. The most commonly used tests are:\n",
        "   - For ğŸ”¢ **continuous features, the [Kolmogorov-Smirnov test](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test)** is a non-parametric hypothesis test that âœ… checks whether **two samples come from the same distribution**. \n",
        "\n",
        "  - For ğŸ· **categorical features, the [Chi-squared test](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test)** checks whether the observed frequencies for a categorical feature in the target data match the expected frequencies seen from the source data.\n",
        "\n",
        "  **P-values** help to detect drift but they ğŸ‘ **do not quantify the ğŸš level of the effect** (they can detect small changes which may be impactless). So it's necessary to complement them with ğŸ’¼ business-significant ğŸ“ metrics. For example, on a large dataset, the average age may have significantly drifted from a statistical perspective, but if the drift is only a few months, this is probably insignificant for many business cases.\n",
        "</details>\n",
        "\n",
        "\n",
        "- <details>\n",
        "  <summary><b>Domain ğŸ· Classifier</b></summary>\n",
        "  \n",
        "  We **train a model that tries to discriminate between the training dataset** **and** the **production dataset**. That is, a **classifier that aims at predicting dataâ€™s origin**. The performance of the model can then be considered as a ğŸ“ metric for the drift ğŸš level.\n",
        "\n",
        " **If this model is ğŸ‘ successful in its task**, and thus has a â¬† high drift score, it implies that **data used at training time and new data can be distinguished**, so itâ€™s fair to say that the **new data has drifted**. To ğŸ” identify the features that are responsible for the drift, one can use the ğŸ“Š **feature importance** of the trained model.\n",
        "</details>\n",
        "\n",
        "  <details>\n",
        "  <summary>Statistical tests ğŸ†š domain ğŸ· classifier</b></summary>\n",
        "  \n",
        "  The ğŸ‘‰ choice between these approaches depends on the required ğŸš level of interpretability. \n",
        "  - If **explainable** methods are **required**, ğŸ”¢ **univariate statistical tests** are prefered. \n",
        "  - If **complex drift** involving several features simultaneously is expected, the ğŸ· **domain classifier** approach may be a ğŸ‘ good option.\n",
        "</details>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Data drift can be identified for different features:\n",
        "\n",
        "- <details>\n",
        "  <summary><b>Drift attributed to the ğŸ¯ target feature</b></summary>\n",
        "  \n",
        "  It's important to ğŸ” identify because it often directly impacts the ğŸ’¼ business (e.g. in a credit score system, if the scores are â¬‡ lower overall, the number of awarded loans will likely be lower, and therefore the ğŸ’° revenues). \n",
        "</details>\n",
        "\n",
        "\n",
        "- <details>\n",
        "  <summary><b>Drift attributed to features</b></summary>\n",
        "  \n",
        "  It's useful to mitigate the impact, as it may hint at the need for:\n",
        "\n",
        "  - âš–ï¸ **Reweighting** according to this feature (e.g., if customers above 60 now represent 60% of users but it was only 30% in the train set, then we can âœ–ï¸ double their weight and â†©ï¸ retrain the model).\n",
        "</details>\n",
        "\n",
        "\n",
        "\n",
        "In all cases, it is **unlikely** that ğŸ¤– **automatic actions** exist if drift is detected. It could happen if it is not ğŸ’° costly to ğŸš€ deploy retrained models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vkS8p5YNDwp"
      },
      "source": [
        "## ğŸ” The feedback loop <a name=\"5\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGt5V2xENGCR"
      },
      "source": [
        "The data ğŸ” feedback loop ([Continuous Delivery for ML](https://martinfowler.com/articles/cd4ml.html)), shows the idea that **information from the production environment â†©ï¸ flows back** to the model prototyping environment **for further â¬† improvement**. \n",
        "\n",
        "\n",
        "<details>\n",
        "  <summary>Image</summary>\n",
        "\n",
        "  ![](https://i.ibb.co/SNnW3vz/0701.png)\n",
        "  - Data collected in the ğŸ–¥ Monitoring and ğŸ” Observability phase is sent â†©ï¸ to the ğŸš§ Model Building phase. \n",
        "  - From there, the system analyzes whether the model is ğŸ‘ working as expected. \n",
        "    - If it's the case, no ğŸ¬ action is required. \n",
        "    - If the modelâ€™s performance is â¬‡ degrading, an update will be triggered, either ğŸ¤– automatically or ğŸ¤š manually by the data scientist. This usually means either â†©ï¸ retraining the model with new labeled data or developing a new model with â• additional features.\n",
        "</details>\n",
        "\n",
        "\n",
        "\n",
        "The ğŸ¯ goal is ğŸ¥… capture the emerging patterns and **make sure that the business is not ğŸ‘ negatively impacted**. In â• addition to the concepts previously discussed, three components that we discuss next are ğŸ— critical:\n",
        "\n",
        "\n",
        "\n",
        "| Component |      Description      |\n",
        "|----------|:-------------:|\n",
        "| âœï¸ **Logging system** |  It collects data from several production servers |\n",
        "| ğŸ“ **Model evaluation store**  | It performs **versioning** and ğŸ“ evaluation between different model versions | \n",
        "| ğŸ†š **Online evaluation**  | It performs **model ğŸ†š comparison** on production environments, either with shadow or A/B testing | "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l53MwQONL87"
      },
      "source": [
        "### âœï¸ Logging <a name=\"5.1\"></a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUHOvhx-NNXW"
      },
      "source": [
        "ğŸ–¥ **Monitoring a live system means ğŸ“ collecting and aggregating data about its states**. Data from these environments need to be centralized in a place to be ğŸ“ˆ analyzed and monitored (either ğŸ¤– automatically or ğŸ¤š manually). This enables continuous â¬† improvement of the ML system. \n",
        "\n",
        "An **event log** of an ML system is a **record with a timestamp and the following information**:\n",
        "\n",
        "\n",
        "| â„¹ Information | ğŸ¤” Description |\n",
        "|----------|:-------------:|\n",
        "| *Model metadata* | Identification of the model and the version |\n",
        "| *Model inputs*  | Feature values of new observations | \n",
        "| *Model outputs* | Predictions made by the model | \n",
        "| *System action* | The ğŸ¬ action made by the system based on the prediction (e.g. in fraud detection, when the model gives a â¬† high probability, the system can ğŸš« block the transaction) | \n",
        "| *Model explanation* | Explanation for the prediction (required in highly regulated domains such as ğŸ¦ finance) | \n",
        "\n",
        "Nowadays, as production ğŸ— infrastructures are getting more complex with several models ğŸš€ deployed simultaneously across several servers, an effective âœï¸ logging system is more important than ever, but there are some requirements and challenges.\n",
        "\n",
        "\n",
        "<details>\n",
        "  <summary>ğŸ“œ Requirements</summary>\n",
        "\n",
        "  - The system can **access and â†©ï¸ retrieve scoring logs from multiple servers**, either in real-time inference or in batch inference.\n",
        "\n",
        "  - When a **model is ğŸš€ deployed on multiple servers**, the system can handle the ğŸ”— **mapping and aggregation of all information** per model across servers.\n",
        "</details>\n",
        "\n",
        "\n",
        "<details>\n",
        "  <summary>âš¡ï¸ Challenges</summary>\n",
        "\n",
        "  - For **large-scale ML applications**, the number of raw event logs generated can be an issue. However, as the ğŸ¯ goal of monitoring is usually to estimate aggregate ğŸ“ metrics, **saving only a subset of the predictions** may be acceptable in many cases. \n",
        "</details>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdI662_PNVO1"
      },
      "source": [
        "### ğŸ“ Model evaluation store <a name=\"5.2\"></a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaBof30ZNX68"
      },
      "source": [
        "With a âœï¸ logging system in place, it periodically fetches data from the production environment for ğŸ“Š monitoring. One day, the data drift ğŸ”” alert is triggered. The model performance is â¬‡ degrading. After ğŸ” review, data scientists decide to â†©ï¸ retrain the model. With several trained candidate models, the â­ next step is to ğŸ†š **compare** them **with the ğŸš€ deployed model**. \n",
        "\n",
        "In practice, this means ğŸ“ evaluating all the models (the candidates as well as the ğŸš€ deployed model) on the same dataset. **If one of the candidate models ğŸ¥‡ outperforms the active model**, there are two ways to proceed: **update the model** on the production environment or move to an **online evaluation**.\n",
        "\n",
        "The model evaluation store is a structure that centralizes the data related to the model lifecycle to allow ğŸ†š **comparing** multiple, newly trained **model versions against versions of ğŸš€ deployed models** or other models on ğŸ· labeled data. It also allows to âœ track model performance over time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4eMBpp5iK2U"
      },
      "source": [
        "### ğŸ†š Online evaluation <a name=\"5.3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0G5i7DjNm5o"
      },
      "source": [
        "There are âœŒ two main modes of online evaluation:\n",
        "\n",
        "- ğŸ¥‡ğŸ¥ˆ **Champion/challenger** (or shadow testing), where the ğŸ¥ˆ candidate model shadows the ğŸ¥‡ deployed model and **scores the same live requests**.\n",
        "\n",
        "- ğŸ…°/ğŸ…± **testing**, where the ğŸ¥ˆ candidate model **scores a portion of the live requests** and the ğŸ¥‡ deployed model scores the others.\n",
        "\n",
        "Note that both cases **require â†©ï¸ ground truth**, so the evaluation will necessarily take âŒ› longer than the lag between prediction and ground truth obtention. In addition, whenever ğŸ¥‡ğŸ¥ˆ **shadow testing** is possible, it should be used **over A/B testing** because it is far simpler to understand and to set up, and whatâ€™s more, it ğŸ” **detects differences more âœˆ quickly**.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPfd6pUSNriZ"
      },
      "source": [
        "#### ğŸ¥‡ğŸ¥ˆ Champion/Challenger (shadow testing) <a name=\"5.3.1\"></a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHdYaV9kNtHM"
      },
      "source": [
        "ğŸ¥‡ğŸ¥ˆ Champion/Challenger  involves ğŸš€ **deploying additional models** (the ğŸ¥ˆ **challengers**) to the production environment. These models receive and **score the same incoming requests as the active one** (the ğŸ¥‡ **champion model**). However, they **don't â†©ï¸ return any response** or prediction to the system: thatâ€™s still the job of the ğŸ¥‡ champion model (the predictions are **simply âœ logged** for further ğŸ“Š analysis). This setup allows âœŒï¸ two things:\n",
        "\n",
        "- <details>\n",
        "  <summary>âœ”ï¸ Verification that the performance of the new models are ğŸ‘ better</summary>\n",
        "\n",
        "  As the two models are scoring on the same data, there is a **direct ğŸ†š comparison of the metric of the two models in the production environment**. This **could also be done ğŸ“´ offline** by using the new models on the dataset made of new requests scored by the ğŸ¥‡ champion model.\n",
        "  </details>\n",
        "\n",
        "- <details>\n",
        "  <summary>ğŸ“ Measurement of how the model handles the âš™ realistic load</summary>\n",
        "\n",
        "  As the new model can have new features or preprocessing techniques, the â³ **prediction time for a request wonâ€™t be the same as that of the original one**. This is the main ğŸ‘ **advantage of doing it online**.\n",
        "  </details>\n",
        "\n",
        "\n",
        "ğŸ“œ Requisites\n",
        "\n",
        "- <details>\n",
        "  <summary>âœ Same information must be logged</summary>\n",
        "\n",
        "  To be able to ğŸ†š compare both champion/challenger models, the **same information must be âœ logged for both** (input and output data, â³ processing time...).\n",
        "</details>\n",
        "\n",
        "- <details>\n",
        "  <summary>â³ Time deployed</summary>\n",
        "\n",
        "  - To make a clear decision about what model performs ğŸ‘ better, both models should be deployed â³ long so that enough predictions are made and metric fluctuations due to randomness are dampened (the difference is significant). This can be assessed ğŸ“‰ graphically by checking that the **metric estimations** are not giggling anymore or by doing a âœ… **statistical test** (a paired sample T-test).\n",
        "</details>\n",
        "\n",
        "\n",
        "ğŸ¤” Considerations\n",
        "- <details>\n",
        "  <summary>ğŸ–¥ Server performance</summary>\n",
        "\n",
        "  If two **memory-intensive models** are called synchronously, they **can ğŸŒ slow the system down**, impacting ğŸ‘ negatively the user experience but also âŒ **corrupt the data collected** about the functioning of the models.\n",
        "</details>\n",
        "\n",
        "- <details>\n",
        "  <summary>ğŸ—£ Communication with external system</summary>\n",
        "\n",
        "  If the two models use an **external API to enrich** their features, that 2ï¸âƒ£ **doubles the number of requests** to these services, thus doubling ğŸ’² costs. If that API service has some **caching system** in place, then the **second request** will be processed much ğŸ **faster** than the first one, which can **bias** the result when ğŸ†š comparing the total âŒ› **prediction time** of the two models. \n",
        "  \n",
        "  **Note**: the ğŸ¥ˆ **challenger may be used only for a random subset of the incoming requests**, which will alleviate the âš™ load at the expense of â¬† increased âŒ› time before a conclusion can be drawn.\n",
        "</details>\n",
        "\n",
        "- <details>\n",
        "  <summary>ğŸ¬ Challenger model does not influence the system's actions anyway</summary>\n",
        "\n",
        "  - **When the challenger model** encounters an unexpected ğŸ› issue and  âŒ **fails, the production environment won't experience any discontinuation or degradation** in terms of â³ response time.\n",
        "\n",
        " - ğŸ¬ **Actions** taken by the system **depend only on the prediction of the ğŸ¥‡ champion model**, and they happen only once. For example, in a fraud detection use case, imagine that by mistake the challenger model is plugged directly into the system, charging each transaction twice (a ğŸ’¥ catastrophic scenario).\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTsw9gwhNzCn"
      },
      "source": [
        "#### ğŸ…°ğŸ…± A/B testing <a name=\"5.3.2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0LKwYeLN1hL"
      },
      "source": [
        "Unlike shadow testing, **with A/B testing, the ğŸ¥ˆ candidate model ğŸ”™ returns predictions for certain requests, and the original model handles the other ones**. Once the test â² period is over, âœ… **statistical tests ğŸ†š compare the performance of the two models**, and teams can make a decision. \n",
        "\n",
        "For ML models, A/B testing **should be used only when ğŸ¥‡ğŸ¥ˆ champion/challenger is not possible**. This might happen when:\n",
        "\n",
        "- <details>\n",
        "  <summary>â†©ï¸ The ground truth cannot be evaluated for both models</summary>\n",
        "\n",
        "  For example:\n",
        "  - For a recommendation engine, the prediction â¡ gives a list of items on which a given customer is likely to ğŸ–± click if they are presented. Therefore, it is impossible to know if the customer would have clicked if it is not presented, so some kind of A/B testing will have to be done. \n",
        "  - For a fraud detection model, as ğŸ‹ heavy work is needed to â†©ï¸ obtain the ground truth, it may not be possible to do it for the positive predictions of two models because it would â¬† increase the workload too much, as some frauds are detected by only one model. As a result, randomly applying only the B model to a small fraction of the requests will allow for the workload to remain â– constant.\n",
        "</details>\n",
        "\n",
        "\n",
        "- <details>\n",
        "  <summary> ğŸ¯ The objective to optimize is only indirectly related to the performance of the prediction</summary>\n",
        "\n",
        "  Imagine an ad engine based on an ML model that predicts if a user will ğŸ–± click on the ad. Now imagine that it is evaluated on the buy rate, i.e., if the user bought the product. It is not possible to record the reaction of the ğŸ§‘ user for two different models, so in this case, A/B testing is the only way.\n",
        "</details>\n",
        "\n",
        "\n",
        "Steps:\n",
        "\n",
        "- â¬…ï¸ Before the A/B test: \n",
        "  - <details>\n",
        "    <summary> ğŸ¯ Define a clear goal</summary>\n",
        "\n",
        "    A ğŸ“ quantitative **business metric** that needs to be optimized. For example, ğŸ–± click-through rate. \n",
        "  </details>\n",
        "\n",
        "  - <details>\n",
        "    <summary>ğŸ‘¬ Define a precise population</summary>\n",
        "\n",
        "    Carefully choosing a segment for the âœ… test along with a âœ‚ splitting strategy that assures **no bias between groups** (experimental design). This may be a random split, but it may be more complex. For example, the situation might dictate that all the requests of a particular customer are handled by the same model.\n",
        "  </details>\n",
        "\n",
        "  - <details>\n",
        "    <summary>ğŸ“œ Define the statistical protocol</summary>\n",
        "\n",
        "    The resulting metrics are ğŸ†š compared using âœ… statistical tests. To make the conclusion robust, teams need to define beforehand the ğŸ“ **sample size** for the desired minimum effect size, which is the minimum difference between the two model's performance metrics. Teams must also fix a âŒ› **test duration**. With similar sample sizes, the power to detect meaningful differences will be lower than with champion/challenger because **unpaired sample tests have to be used**.\n",
        "  </details>\n",
        "\n",
        "\n",
        "- During the A/B test: \n",
        "\n",
        "  - <details>\n",
        "    <summary>âŒ› Test period</summary>\n",
        "\n",
        "    - Fixed-horizon test (frequentist): If the **experiment is ğŸ›‘ stopped before the test duration is over** (even if the âœ… statistical test starts to return a significant metric difference), it can produce **biased results** due to cherry-picking the desired outcome (**p-hacking**). By other hand, the test is running live, and in a commercial environment, every bad prediction is likely to cost ğŸ’² money, so not being able to ğŸ¤š stop a test early could be expensive.\n",
        "\n",
        "    - **Multi-arm bandit** tests (bayesian) draws conclusions ğŸ quicker. It's **adaptive** (the algorithm that decides the split between models adapts according to live results and â¬‡ **reduces the âš™ workload of underperforming models**). While this testing is **more complex**, it can reduce the business ğŸ’² cost of sending ğŸš¦ traffic to a ğŸ‘ poorly performing model.\n",
        "  </details>\n",
        "\n",
        "\n",
        "- <details>\n",
        "  <summary>â¡ï¸ After the A/B test: </summary>\n",
        "\n",
        "  Once the âŒ› test duration is over, ğŸ” check the collected data to make sure that the quality is ğŸ‘ good. From there, run the âœ… statistical tests; if the ğŸ“ metric difference is statistically significant in favor of the ğŸ¥ˆ candidate model, the original model can be â© replaced with the new version.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIcVuXQhyJ8-"
      },
      "source": [
        "# ğŸ““ References <a name=\"6\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7e2-9wRgQTB"
      },
      "source": [
        "- [MLOps: Continuous delivery and automation pipelines in machine learning](https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)\n",
        "\n",
        "- [Introducing MLOps](https://www.oreilly.com/library/view/introducing-mlops/9781492083283/)\n",
        "\n",
        "- [MLOps.Community](https://www.youtube.com/channel/UCG6qpjVnBTTT8wLGBygANOQ)"
      ]
    }
  ]
}