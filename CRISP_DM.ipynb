{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CRISP-DM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Iy4DnXiYBVhI",
        "oCFnKe0cI5xf",
        "F3tsoSkfOC8i",
        "f8Pt_uZ9PwBr",
        "MqxUOQM8Uo6a",
        "SRoDPEGL9S09",
        "Hnn3XfpM_yxA",
        "QEgaZaKeDlaC",
        "XVuea9CrECpP",
        "sYkLdhERGgFG",
        "uVoN1EEoI0Bo",
        "bWqaBLaCQWgH",
        "mrTKGBEkVDVX",
        "SfcavErjV28B",
        "-VnRLZMLWZin",
        "O0d8ODr4Wb5H",
        "go2fSyj8Wgvi",
        "AN61-zfAWoyY",
        "ZZMR0XJmW8Is",
        "jGlGNgro8_nV",
        "q1grfWcx9Cng",
        "cBfwwTk79JAP",
        "oOzUtIy49Nla",
        "qd6gJGZW9rqF",
        "GXrSPNskGm3q",
        "Lt3HbEvTGtbd",
        "lXEu0EzwGxM3",
        "x7Gv0YcI9zQB",
        "hFQq29unHEe_",
        "Q_7nreVxHIgR",
        "9NiSsgAdHLuB",
        "45AEOrgqHP1w",
        "rHUXtW2_4qXd"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOjNwkaAgrWV/c5d8dlYQdJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorviro/Machine-Learning-Python/blob/master/CRISP_DM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtJFC8h2JpK4"
      },
      "source": [
        "# CRISP-DM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy4DnXiYBVhI"
      },
      "source": [
        "# Table of contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMeyaWj5BYca"
      },
      "source": [
        "1. [ℹ️ Introduction](#1)\n",
        "2. [👨‍💼 Business understanding](#2)\n",
        "  1. [🎯 Determine the business objectives](#2.1)\n",
        "  2. [🔎 Asses the situation](#2.2)\n",
        "  3. [🤔 Determine the data mining goals](#2.3)\n",
        "  4. [📋 Produce a project plan](#2.4)\n",
        "3. [🧐 Data understanding](#3)\n",
        "  1. [⚙️ Collect the initial data](#3.1)\n",
        "  2. [👀 Describe the data](#3.2)\n",
        "  3. [📉 Explore the data](#3.3)\n",
        "  4. [🐛 Verify data quality](#3.4)\n",
        "4. [🧑‍🔧 Data preparation](#4)\n",
        "  1. [👉 Select data](#4.1)\n",
        "  2. [🧹️ Clean data](#4.2)\n",
        "  3. [👷 Construct data](#4.3)\n",
        "  4. [⛓ Integrate data](#4.4)\n",
        "  5. [🪛 Format data](#4.5)\n",
        "5. [🧙 Modeling](#5)\n",
        "  1. [👉 Select the modeling technique](#5.1)\n",
        "  2. [✔️ Generate test design](#5.2)\n",
        "  3. [🏗️ Build and train the model](#5.3)\n",
        "  4. [🔎 Assess the model](#5.4)\n",
        "6. [🕵️ Evaluation](#6)\n",
        "  1. [🧐 Evaluate results](#6.1)\n",
        "  2. [⭐ Review process](#6.2)\n",
        "  3. [⏩ Determine next steps](#6.3)\n",
        "7. [🚀 Deployment](#7)\n",
        "  1. [📋 Plan deployment](#7.1)\n",
        "  2. [🖥️🔧 Plan monitoring and maintenance](#7.2)\n",
        "  3. [📄 Produce final report](#7.3)\n",
        "  4. [✨ Review project](#7.4)\n",
        "8. [📘 References](#8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCFnKe0cI5xf"
      },
      "source": [
        "# ℹ️ Introduction <a name=\"1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L86SDKpOH_Au"
      },
      "source": [
        "CRISP-DM (*CRoss-Industry Standard Process for Data Mining*) is a **data mining methodology and process model** that provides a complete **📋 blueprint for conducting a data mining project**. CRISP-DM is **based on practical, real-world** data mining 👨‍💼 **experience**. It highlights the fact that a data mining project does not finish once a well-suited model is built, it has to be 🚀 deployed, 🔧 maintained, and 🖥 monitored but also exhaustively 📝 documented so that other data mining projects (or 🔄 iterations of the same project) can benefit from the knowledge gain and work from it.\n",
        "\n",
        "- As a methodology, it includes **descriptions of the phases of a project**, the **tasks needed in each phase**, and an explanation of the 🔗 relationships between tasks. \n",
        "- As a process model, CRISP-DM offers a summary of the **life cycle of a data mining project**, breaking it down into **6️⃣ phases** shown in the following figure:\n",
        "\n",
        "![](https://www.ibm.com/docs/es/SS3RA7_sub/modeler_crispdm_ddita/clementine/images/crisp_process.jpg)\n",
        "\n",
        "The **arrows** indicate frequent and important **dependencies between the phases**. The sequence of the phases is **not strict** ↕️ (a project can forward and backward between phases if it's necessary). The 🔄 **outer circle** symbolizes the **cyclical nature of data mining** itself and illustrates that the lessons learned during the data mining process can trigger new model iterations that will benefit from previous experiences.\n",
        "\n",
        "The CRISP-DM is **flexible**. For example, if a company wants to understand better the behavior of their customers, the work can focus on exploring and 📊 visualizing the data to obtain insights into the behavior of the customers. In this situation, the phases of modeling, evaluation, and deployment can be less relevant than the phases for data understanding and data preparation. However, it's important to consider some questions that emerge during the posterior phases for the planning of long-term and future data mining objectives.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3tsoSkfOC8i"
      },
      "source": [
        "# 👨‍💼 Business understanding <a name=\"2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH8VdZn6OGCH"
      },
      "source": [
        "An important phase of any data mining project is **understanding the project objectives and expectations from a 👨‍💼 business perspective**. We can then use that knowledge to **define a data mining problem and a 📝 preliminary plan** designed to achieve the objectives.\n",
        "\n",
        "The business understanding phase involves several **key steps or tasks**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8Pt_uZ9PwBr"
      },
      "source": [
        "## 🎯 Determine the business objectives <a name=\"2.1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgo8MTt-QNPY"
      },
      "source": [
        "The first step of the project is to understand, from a 👨‍💼 business perspective, **what the client wants to achieve** and describe **criteria to consider whether the project's result is ✅ valid** or useful.\n",
        "\n",
        "- Identify the **area of the problem** (e.g., marketing, customer service, business development, etc).\n",
        "- **Describe the problem** to be solved in a general and informal manner. E.g., \"retain current customers\" or \"encourage customer loyalty with a more personalized service\".\n",
        "- Define the requirements of the project: motivation, objectives, success criterion.\n",
        "- Identify the **key people and roles**. Who will be the **project owner?**. Who will evaluate the criteria of success? **What business units will be affected by the data mining project?**\n",
        "- Specify all **related business ❓ questions** and other nuances. E.g., \"will lower fees reduce the number of customers who leave?\" or \"Are some customers more important than others?\"\n",
        "- Identify the needs and expectations of customers.\n",
        "- Specify **advantages expected in business terms** (e.g., \"reduce lost customers\").\n",
        "- If the project is an evolution of another project, **analyze the current solution** (pros and cons, acceptance level,...). \n",
        "- **Specify in detail ☑️ success criteria** (e.g., \"reduce lost customers by 10 percent\" or \"customers spend more time and view more pages on the site per visit\"). Each **success criterion** must 🔗 **relate** to at least one of the specified **business objectives**. The success criteria can also be subjective (e.g., discover groups of customers with similar behavior)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqxUOQM8Uo6a"
      },
      "source": [
        "## 🔎 Asses the situation <a name=\"2.2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y025lMX1UrXG"
      },
      "source": [
        "This step implies a 🧐 detailed **investigation of resources available**, to accomplish the data mining project. From personnel to data available, 💻 computational resources, and software.\n",
        "\n",
        "- Identify basic 💾 **hardware and its availability** for the data mining project.\n",
        "- Identify **data sources, their type** (database, stream sources, external sources...), and their **correct access**.\n",
        "- Check 🛠️ **tools** and techniques **available**.\n",
        "- Identify **system admin, database admin, technical support personnel, business domain experts**, for future questions.\n",
        "- Identify 👩‍💻 **market analysts, data mining experts** and check **their availability**.\n",
        "\n",
        "\n",
        "List the **requirements** of the project. While the main requirements are the business objectives mentioned in the previous task, it's necessary to consider other elements.\n",
        "\n",
        "- Are there 🧑‍⚖️ **legal or 🔒 security constraints about the data or project results**?, Is the use of the data allowed?\n",
        "- Are there **requirements about the 🚀 deployment of the results**? E.g. will the results show in a 🌐 web app? or will they store in a database for later consumption? If the results are predictions, what is the latency required (batch vs online inference)?\n",
        "\n",
        "List **assumptions about the data or the business**.\n",
        "\n",
        "- List assumptions done about **data quality** (accuracy, availability). There is a **minimum 🎚 level of quality** of the results?\n",
        "- Identify **external factors** (like economic factors) that can affect the project (e.g. competency products)\n",
        "- How does the project team expect to view the results? Do they want to **understand the model or simply view the results?** How important is the level of interpretability of the results?\n",
        "\n",
        "\n",
        "List **constraints** about availability of resources, technological (amount of data)\n",
        "\n",
        "- **Legal** constraints about the **use of the data**\n",
        "- 💰 **Budget** constraints (fixed costs, implementation costs)\n",
        "- Check if the **data is 🚫 accessible**\n",
        "\n",
        "\n",
        "Identify the **project risks** or events that can delay the project and **list potential solutions** to those risks. \n",
        "\n",
        "- 🗓 Scheduling: What happens if the project takes longer than scheduled? \n",
        "- 💸 Financial: What happens if the project sponsor detects budgetary problems?\n",
        "- Data: What happens if the data is of poor quality or coverage?\n",
        "- Results: What happens if the initial results are not so good as expected?\n",
        "\n",
        "Finally, construct a **cost-benefit analysis** for the project\n",
        "\n",
        "- Estimate 💲 **cost of data collection, operationalization and deployment**.\n",
        "- Identify the **benefits of the business objective** (e.g. improve customer satisfaction, ROI, increase profits), and **additional benefits** such as the knowledge acquired from 📊 data exploration or possible benefits from a better comprehension of the data\n",
        "\n",
        "To make sure the business and data mining \"speak the same language\" we can generate a 📝 **glossary of business and data mining terms** (especially, terms that can generate confusion) with illustrative examples related to the business problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRoDPEGL9S09"
      },
      "source": [
        "## 🤔 Determine the data mining goals <a name=\"2.3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RsjoFGw9VJF"
      },
      "source": [
        "The data mining goal **translates project objectives in business and technical terms**. If the business goal cannot be translated into a data mining goal, it may be wise to 🤚⏪ consider redefining the problem at this point. For **example**, the business objective \"retain current customers\" can be translated into a data mining goal like \"predict the churn likelihood of each customer given the data about their purchases, behavior...\". If this data mining goal is accomplished, it can be used by the company to retain current customers (e.g. send offers with discounts to customers who are likely to churn).\n",
        "\n",
        "It's necessary also to **define ☑️ success criterion in technical terms** (e.g. certain 🎚 level of predictive accuracy). \n",
        "\n",
        "- Describe expected outputs of the project (usually techniques) which allow the achievement of the business objectives\n",
        "- Translate business questions to data mining objectives 🎯 (e.g. customer segmentation by using a clustering algorithm)\n",
        "- Specify the **type of the data mining problem** (\n",
        "🏷️ classification, 📈 regression, clustering, etc).\n",
        "- Specify **success criterion to evaluate the model** (accuracy, complexity, interpretability). Define tests for this criterion and threshold values.\n",
        "- Specify rules to apply **subjective evaluation criterion** (e.g. descriptive ability of the model). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnn3XfpM_yxA"
      },
      "source": [
        "## 📋 Produce a project plan <a name=\"2.4\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgrN1sfc_0Ve"
      },
      "source": [
        "Make a **plan for achieving the data mining 🎯 goals** (and therefore business objectives). The **questions** that have posed so far and the **business and data mining objectives** formulated will **form the basis of this plan**. It must include the **steps** to perform during the rest of the project (for each step, its ⏲ duration, **resources** required, dependencies), an assessment of **potential risks**, and an initial assessment of the 🔧 **tools and techniques needed** to support the project. \n",
        "\n",
        "This plan is **dynamic**. At the end of each phase, we can **review** the progress and achievements, and ✍️ **update it if it is necessary**. Review points for these updates are part of the plan.\n",
        "\n",
        "- Estimate the **effort and resources required** to develop the solution.\n",
        "- Estimate the ⏳︎ **duration of each phase** of the project\n",
        "- Identify 🔑 critical steps of the project\n",
        "- Define **review and decision 📆 points**\n",
        "- Identify the phases with more iterations (modeling)\n",
        "- Create a list with **criteria for selecting ⚒️ tools** and techniques. Evaluate if they are adequate for the problem.\n",
        "- Define the project plan and 🤝 **discuss** its viability **with all personnel involved**.\n",
        "- Combine all objectives identified and techniques selected into a coherent procedure that tackles the business objectives and defines the success criterion.\n",
        "\n",
        "An example of a simple project plan is available [here](https://www.ibm.com/docs/en/spss-modeler/SaaS?topic=plan-sample-project)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEgaZaKeDlaC"
      },
      "source": [
        "# 🧐 Data understanding <a name=\"3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAHg-IvGDrJS"
      },
      "source": [
        "It starts with an **initial data collection** and continues **getting familiarity with the data**, identify **data quality 🐛 problems**, discover **initial 📊 insights** from the data, or detect interesting subsets to formulate ❔ hypotheses about hidden information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVuea9CrECpP"
      },
      "source": [
        "## ⚙️ Collect the initial data <a name=\"3.1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5Sk4givEGrj"
      },
      "source": [
        "In this task we **acquire** the necessary **data** that is listed out in the resources of the project (including data access, and loading and integrating this data if it's necessary). \n",
        "\n",
        "We can create a 📝 **report with the data sets**, the **data sources** (existing data, additional data), the **methods used to acquire them, and problems encountered and the solutions** adopted to aid with future replications of the project (e.g., when collecting data from different sources, some of these sources may have a long lag time, it is helpful to know this in advance to avoid potential delays).\n",
        "\n",
        "- Specify **data selection criterion** (e.g., **what attributes are necessary** for the data mining 🎯 objectives and what not? why? how many attributes can we manage with the techniques selected?)\n",
        "- **Is there enough amount of data** to obtain conclusions or accurate predictions?\n",
        "- **Be careful with 🐛 data quality** issues **when collecting data from different data sources**. E.g, are missing values managed equally in the data sources?\n",
        "- **If data is 🖼️ unstructured, how** do will **encode** it to be modeled?\n",
        "- Can we automate the data extraction process?\n",
        "\n",
        "An example of a data collection report is available [here](https://www.ibm.com/docs/en/spss-modeler/SaaS?topic=data-e-retail-example-initial-collection)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYkLdhERGgFG"
      },
      "source": [
        "## 👀 Describe the data <a name=\"3.2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYjBOH8DGlB5"
      },
      "source": [
        "In this task, we examine the **surface properties of the acquired data and ✍️ report on the results**, examining 🐛 **data issues** such as its **format, its quantity**, and other surface features (**basic statistics**). The 🗝 key question to ask is: **Does the data acquired satisfy the relevant requirements?** E.g., if age is an important field and the data does not reflect the entire age range, it may be wise to collect a different set of data. This step also provides a basic understanding of the data on which subsequent steps will build.\n",
        "\n",
        "- Describe data tables and their ⛓ relationship\n",
        "- Analyze **data volume** and data complexity\n",
        "- Check accessibility and availability of attributes\n",
        "- Check **attribute types** (🔢 numerical, 🏷 categorical, etc)\n",
        "- Check the **range of values** of the attributes\n",
        "- Analyze **correlation** between attributes and key 🔗 relationships\n",
        "- Understand the **meaning of the attributes** and classify (describe) its values in business terms. Are they **coherent?**\n",
        "- Compute **basic statistics of the attributes** (📊 distribution, mean, standard deviation, etc) and relate the results with their meaning in business terms\n",
        "- Decide if the attribute is useful ✅ for the data mining 🎯 objectives\n",
        "- Interview 👨‍💼 **business domain experts** and get **their opinion about the importance of the attributes**\n",
        "- Decide if it's necessary to ⚖️ **balance the data** (in unbalanced datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVoN1EEoI0Bo"
      },
      "source": [
        "## 📉 Explore the data <a name=\"3.3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNYAKVXWI1aY"
      },
      "source": [
        "This task tackles the data mining questions that can be addressed using **querying** (e.g., what types of products the customers in a particular group usually buy?), 📊 **visualization** (e.g., uncover potential fraud patterns), and **reporting** (distribution of related attributes, **aggregations**, significative **properties of subpopulations**, basic statistics). \n",
        "\n",
        "Finally, we can create a **data exploration 📄 report** that **outlines first findings, initial hypothesis**, and the potential impact on the remainder of the project.\n",
        "\n",
        "- Analyze in detail the **properties of interesting attributes** (basic statistics, interesting **subpopulations**...). What attributes look 🥇 promising for future analysis? \n",
        "- Has this exploration revealed new characteristics of the data? \n",
        "- **Formulate ❔ hypothesis** and convert them in data mining objectives if it's possible\n",
        "- **Clarify data mining 🎯 objectives**. Has this exploration modified the objectives?\n",
        "- Perform **basic analysis to ✔️ verify the hypothesis**. Has this exploration modified the initial hypothesis?\n",
        "- Consider and evaluate information and conclusions of the previous task of describing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWqaBLaCQWgH"
      },
      "source": [
        "## 🐛 Verify data quality <a name=\"3.4\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GfMjPTZQZMm"
      },
      "source": [
        "Real-world data is often messy 🙈. In this task, we examine the quality of the data. Is the **data complete?** Do data **cover all cases?** Are values correct or contain 🐛 **errors?** If there are errors, **how often do they occur?** Are there **missing values?** If there are, how are they represented, when, and how often? Other common items to check include: the plausibility of values; the spelling of values; **attributes values that conflict with common sense** (e.g., teenagers with high income❗).\n",
        "\n",
        "- Check the **coverage** of data (are all possible values represented?)\n",
        "- Check the **meaning of the attributes 🔗 matches with their values**\n",
        "- Identify **missing and blank values**\n",
        "- Establish the **cause** and meaning **of missing or erroneous data**, and check attributes with similar meaning that have very different values\n",
        "- 🧐 Check the orthography and format of values (e.g., the same value but sometimes it starts with lowercase and sometimes it starts with a capital letter)\n",
        "- Check **deviations (outliers)** and establish if they **are noise or** they can indicate **interesting phenomenons** 🤔\n",
        "- Check the plausibility of values (e.g, attributes with almost always the same value)\n",
        "- Check noise and **inconsistencies between sources** ⚠️\n",
        "- Sometimes we can exclude some data if it has no enough quality or if it does not have valid information for the business or the data mining problem.\n",
        "\n",
        "Based on the exploration and verification of data quality, we can prepare a **data quality 📝 report** that will guide the next phase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrTKGBEkVDVX"
      },
      "source": [
        "# 🧑‍🔧 Data preparation <a name=\"4\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIMUHQO0VPAF"
      },
      "source": [
        "The data preparation phase covers all activities to 👷 **construct the final data set** (data that will be **fed into the modeling** tools) from the initial raw data. This phase usually takes 50-70% of a project's ⌛️ time and effort. Devoting adequate effort to the earlier 👨‍💼 business understanding and 🧐 data understanding phases can minimize this overhead, but we still need to spend a good amount of effort preparing and packaging the data for mining.\n",
        "\n",
        "Tasks include 👉 attribute selection, as well as transformation, and 🧹️ cleaning of data for modeling tools."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfcavErjV28B"
      },
      "source": [
        "## 👉 Select data <a name=\"4.1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP7Q1QcUWOaq"
      },
      "source": [
        "**Deciding on the data** that will be used for the analysis is **based on several criteria**: its **relevance** to the data mining 🎯 goals, **quality, and technical constraints** (such as limits on data volume or data types). Some tasks of this phase can be:\n",
        "\n",
        "- Define the **data ✔️ included and ❌ excluded**, and the **reasons** for that decision. We can perform **correlation** tests (or other methods for selecting important features) **to decide which attributes include**. It is also a good idea to decide if one or more attributes are more important than others 🥇🥈🥉.\n",
        "- Collect additional appropriate data (from internal or external sources)\n",
        "- **Reconsider the data selection criterion** (from the \"Collect initial data\" phase) **by the real 🎚 quality of the data** and the results from data exploration and modeling.\n",
        "- Are there any **constraints** on using particular fields such as gender or race or sensitive information?\n",
        "- Select different **data subsets** (e.g. different attributes, only data that verify certain conditions, etc)\n",
        "- Consider the use of **sampling techniques** \n",
        "\n",
        "Based on the exploration and verification of data quality, we need to prepare a **📝 report** with all this information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VnRLZMLWZin"
      },
      "source": [
        "## 🧹️ Clean data <a name=\"4.2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSodMsAXWbU6"
      },
      "source": [
        "If necessary, we can ⬆️ **increase the quality of the data** to the level required for the analysis techniques selected. This can imply **select 👌 clean subsets** of data **or** incorporate techniques for **estimating missing data** through modeling analyses (or by adequate default values). ✍️ **Report how we address each quality problem** reported in the earlier \"Verify Data Quality\" step (see data quality 📄 report).\n",
        "\n",
        "- Consider how to treat any **noise** observed. We can correct it, 🔥 remove it, or 🤷 ignore it.\n",
        "- Decide how to treat **missing values**. We can exclude rows or attributes or we can fill blanks with an estimated value (mean, mode, regression, KNN...).\n",
        "- **Reconsider the data selection criterion** (from the \"Collect initial data\" phase) **by the 🎚 quality of the data after the cleaning** process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0d8ODr4Wb5H"
      },
      "source": [
        "## 👷 Construct data <a name=\"4.3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUCtTlyJWgWA"
      },
      "source": [
        "This task involves data preparation operations such as **creation of new records, 🤔 derived attributes** (these should only be added if they ease the model process or facilitate the modeling algorithm) or single-attribute **transformations**, usually performed **to fit the needs of the 🛠 modeling tools** (such as one-hot encoding or normalization). This task is also called \"Feature engineering\".\n",
        "\n",
        "- Build derived attributes, create new records, or transform existent attributes\n",
        "- Decide if **data** need be **normalized** before modeling\n",
        "- Consider adding information about the 🥇🥈🥉 **importance of attributes** (attributes with **weight**, weighted normalization)\n",
        "- Specify transformation steps necessary to execute the operations (e.g. binning a 🔢 numeric attribute)\n",
        "- Execute the transformation steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go2fSyj8Wgvi"
      },
      "source": [
        "## ⛓ Integrate data <a name=\"4.4\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU6RIR5kWjM8"
      },
      "source": [
        "Integrating data involves **combining information from multiple\n",
        "tables or records to create new records or values.** With table-based data, an analyst can 🔗 **join** tables that have different information (attributes) about the same objects or ↪️ **concatenate** tables that have the same attributes but different records. \n",
        "\n",
        "- ✅ Check if **integration applications can integrate the input sources** as required\n",
        "- Integrate sources and consider 💾 **saving the resulting output** before proceeding to modeling. \n",
        "- **Reconsider the 👉 data selection criterion** (from the \"Collect initial data\" phase) **by the results of ⛓ data integration** \n",
        "- Perform **aggregations**, operations where **new values are computed by summarizing information from multiple records/tables**. E.g. we have two tables of 👟👠👢 products and product sales, we can compute an aggregation in the table of sales to create a new attribute in the table of products: \"Number of sales of a product in the last 6 months\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN61-zfAWoyY"
      },
      "source": [
        "## 🪛 Format data <a name=\"4.5\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOHCTGq2WqMx"
      },
      "source": [
        "We **maybe need to change the format or design of the data**. Sometimes these changes are needed to make the data suitable for a specific modeling 🛠 tool. These changes might be simple (like trimming strings to a maximum length) or more complex (like order sequential data such as a 📈 time series). Some tasks of this phase can be:\n",
        "\n",
        "- Which models do we plan to use?\n",
        "- Do these **models require a particular data format or order?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZMR0XJmW8Is"
      },
      "source": [
        "# 🧙 Modeling <a name=\"5\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qps_2lHXAD-"
      },
      "source": [
        "Modeling is usually conducted in 🔄 **multiple iterations**. It's rare for a data mining question to be answered satisfactorily with a single model and a single execution. In this phase, **various modeling techniques** are 👉 **selected** and applied and their **parameters are tuned** to optimal values. Typically, several techniques exist for the same data mining problem type. Some techniques have specific requirements in the form of data. Therefore, **stepping ↩️ back to the data preparation phase may be necessary**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGlGNgro8_nV"
      },
      "source": [
        "## 👉 Select the modeling technique <a name=\"5.1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6YRa7Am9Ag2"
      },
      "source": [
        "This task refers to **choosing** one or more specific **modeling techniques**, such as decision 🌿 tree or 🧠 neural network. If assumptions are attached to the modeling technique, these should be recorded.\n",
        "\n",
        "- Decide **appropriate techniques for the problem**, taking into account the tool selected previously\n",
        "- **Register** all **modeling techniques** that will be used\n",
        "- Analyze every **assumption and requirement attached to the modeling technique** (comparing it with the 📄 report of data description) and make sure they are still valid\n",
        " - Are there any assumption about the **data size**, or about the **data distribution**? \n",
        " - Does the model require a certain 🎚 **level of data quality**? Can we meet this level with the current data? \n",
        " - Some data mining techniques require specific data types. Have the data the **proper type** for a particular model? If not, can we make the necessary conversions using data manipulation operations? 🏷 Categorical variables can be transformed to 🔢 numerical (e.g one-hot) and vice-versa (e.g binning)\n",
        " - If our **data is unbalanced**, does the model provide a way to give more importance to rare events (e.g with weights)? If not, we can step ↩️ back to the data preparation phase and ⚖️ balance our data\n",
        " - 📝 **Document** any **data assumptions** as well as any **data manipulations made** to meet the model's requirements. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1grfWcx9Cng"
      },
      "source": [
        "## ✔️ Generate test design <a name=\"5.2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL20Pj6q9GIP"
      },
      "source": [
        "After building a model, we must ✅ **test the model’s quality and validity**. It's appropriate to **design the test procedure before building the model**; this also has implications for data preparation. In supervised data mining tasks, we typically ✂️ **separate the data set into train and test sets**, build the model on the train set, and estimate its quality on the separate test set. We can choose more sophisticated evaluation strategies like **cross-validation**. Some tasks of this phase can be:\n",
        "\n",
        "- **Describe** the criteria for \"goodness\" or **metrics** of a model (↩️ check the success criterion defined in the phase \"Determine the data mining goals\"). Check there are ✔️ **tests for each data mining objective**\n",
        "- **Define and prepare the data** on which these criteria will be tested. How do we separate the data set?\n",
        "- Defined necessary steps (iterations number, objective metrics, etc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBfwwTk79JAP"
      },
      "source": [
        "## 🏗️ Build and train the model <a name=\"5.3\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a15rtTa9Kcd"
      },
      "source": [
        "Once the training data has been selected, the data analyst **runs the modeling 🛠 tool to create one or more models**. The **parameters** are 👌 **adjusted and reported with their values** and the reasons for the values chosen. In order to reproduce our results, we must keep 📝 **notes on the settings and data used** for each model. Here, an experiment tracking tool like (like [MLflow](https://www.mlflow.org/docs/latest/tracking.html) or [W&B](https://wandb.ai/site)) can help. At the end of this phase, the **models** are obtained. It's necessary **describe and interpret** them and ✍️ document each difficulty found with their meanings. Some tasks of this phase can be:\n",
        "\n",
        "- Adjust the parameters of the model. Once the **parameters that produce the 🥇 most accurate results** are adjusted, 💾 **save the model** and ✍️ take **notes on the optimal settings**.\n",
        "- **Describe** in detail the **model and the results**:\n",
        " - Are there **new insights** or unusual patterns **revealed by the model**? \n",
        " - Were there **execution problems** for the model? How reasonable was the **processing ⌛️ time**?\n",
        " - Did the model have **difficulties with data quality 🐛 issues**, such as a high number of missing values? \n",
        " - Express conclusions obtained by the model\n",
        " - For 📏 **based-rule models**, list out the **rules produced**, the evaluation for each rule, etc\n",
        " - For ⬛ **black-box models**, list out **technical information** about the model and **describe the behavior** produced by the modeling process\n",
        " - Describe the **interpretability** of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOzUtIy49Nla"
      },
      "source": [
        "## 🔎 Assess the model <a name=\"5.4\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EslhGuao9S4W"
      },
      "source": [
        "The **models** have to be **interpreted based on domain knowledge, data mining success criteria, and the desired ✔️ test design**, and evaluated according to **evaluation criteria** (in technical terms), but business analysts and 👨‍💼 **domain experts** can interpret the results in the **business context**. The **output** of this phase should be a **summary of the evaluation results**, and a 🥇🥈🥉 **ranking of the models** based on their quality obtained (in terms of evaluation criteria e.g accuracy). Some tasks of this phase can be:\n",
        "\n",
        "- **Evaluate the models** which concern evaluation criterion\n",
        "- Perform a **ranking** taking into account the success and evaluation criterion and select the 🥇 best models\n",
        "- **Interpret the results in business terms** (as much as possible in this phase). Get comments of the model by data experts and 👨‍💼👩‍💼 business domain experts\n",
        "- Check the credibility and reliability of the model.\n",
        "- Check the **effects on the data mining 🎯 objectives**\n",
        "- Compare the models against a particular knowledge base to check if the information revealed is new and useful\n",
        "- Analyze the **potential for the development of each result**\n",
        "- If there is a verbal description of the model generated (e.g in form of rules), evaluate the rules\n",
        "- Analyze specific aspects of each modeling technique and determine if it's **possible to perform adjustments in the parameters to obtain better results**  \n",
        "- Based on the model evaluation, the parameters of the model can be reviewed and adjusted for the following 🔁 iterations to find a better model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd6gJGZW9rqF"
      },
      "source": [
        "# 🕵️ Evaluation <a name=\"6\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4iipFyE9tHi"
      },
      "source": [
        "**Before the deployment** of the model built, it is important to more 🧐 **thoroughly evaluate the model** and review the model’s construction to check if it **properly achieves the business 🎯 objectives**. Here it is critical to **determine if some important business issue has not been sufficiently considered**. At the end of this phase, there should be **a decision about how to use the data mining results**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXrSPNskGm3q"
      },
      "source": [
        "## 🧐 Evaluate results <a name=\"6.1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4YRHrl6GpvF"
      },
      "source": [
        "The previous evaluation step dealt with factors such as the accuracy and generality of the model (data mining criteria). This step 📏 **assesses** the degree to which the **model meets the business 🎯 objectives in terms of business success criteria and determines if there is some business reason why this model is ⚠️ deficient**. \n",
        "The evaluation also seeks to unveil additional challenges and information for future directions. Once the **models** generated **meet the criteria** selected, they are ✅ **approved for inclusion in the final 📄 report**. This list should include models that satisfy both the data mining and business goals.\n",
        "\n",
        "This step requires a clear understanding of the stated business goals, so we have to include key decision makers in the project assessment. Some tasks in this phase can be:\n",
        "\n",
        "- **State clearly the results** in a form that can be easily presented\n",
        "- **Check the effect, interpret, evaluate, estimate and 🥇🥈🥉 rank the results in terms of their applicability to the business goals** (business success criterion). In general, how well do the results answer the business goals? \n",
        "- 🖊️ **Highlight novel** or unique **findings** and ❔ questions the results have raised in business terms\n",
        "- Test the model(s) on real-world applications if ⏳time and 💲budget constraints permit\n",
        "- Compare the models against a particular knowledge base to check if the information revealed is new and useful\n",
        "- Determine if there are **new business 🎯 objectives** for a possible following iterations of the project or for new projects\n",
        "- Annotate recommendations for future data mining projects "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt3HbEvTGtbd"
      },
      "source": [
        "## ⭐ Review process <a name=\"6.2\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wPxD0IlGula"
      },
      "source": [
        "It is now appropriate to do a **🔎 thorough review of the data mining engagement** to determine if there are any important factor or task that has somehow been overlooked. This review also covers **quality assurance** 🐛 issues (e.g. did we correctly build the model? Did we only use allowable attributes that are available for future deployment?). At the end of this phase, there should be a 📃 **summary of the review process**, with the **activities** done **and decisions** made **for each phase**.\n",
        "\n",
        "- Describe the data mining process. Consider the following ❔ **questions for each phase** of the project. \n",
        " - Did this stage contribute to the value of the final results?  \n",
        " - Did it execute optimally? \n",
        " - How can it be improved? \n",
        " - Identify 👎 failures, mistakes, and deviations. How can they be avoided next time? \n",
        " - Identify alternative decisions or strategies that might have been used in a given phase, and ✍️ note them for future data mining projects.\n",
        "- Review the data mining results regarding to the business success ✅ criterion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXEu0EzwGxM3"
      },
      "source": [
        "## ⏩ Determine next steps <a name=\"6.3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJXjv5CaGypG"
      },
      "source": [
        "At this stage, the project leader must **decide whether** to:\n",
        "\n",
        "- **Continue to the 🚀 deployment** phase. If the results address our data mining and business goals we can incorporate the model results into our business process and produce a final report\n",
        "- Initiate **further 🔄 iterations**. If we find that our results are not optimal, we can go back and refine or replace our models. We can take what we've learned and use it to refine the models and produce better results\n",
        "\n",
        "At the end of this phase, there should be a 📋 **list of potential future actions**, with the pros and cons of each option, as well as a decision about how to proceed, with a justification. Some tasks in this phase can be:\n",
        "\n",
        "- Analyze the potential for the development and the improvement of each result\n",
        "- Check the remaining 💻 resources and 💰 budget to determine if they allow additional iterations of the process\n",
        "- Refine the process plan\n",
        "- 🏷 Classify the possible actions, 👉 select one, and 📝 document the reasons for the choice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7Gv0YcI9zQB"
      },
      "source": [
        "# 🚀 Deployment <a name=\"7\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLpsplD090pp"
      },
      "source": [
        "Model creation is not the 🔚 end of the project. Deployment is the process of using the insights gained to make improvements within the organization. This often involves **applying \"live\" models** within an organization’s **decision-making processes** such as real-time personalization. Alternatively, deployment can mean that we **use the insights** gained from data mining **to elicit change** in our organization.\n",
        "\n",
        "The 🗝 key steps here are 📋 planning and 🖥 monitoring the deployment of results, the production of a final 📄 report, and a review of the project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFQq29unHEe_"
      },
      "source": [
        "## 📋 Plan deployment <a name=\"7.1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOVWbIS-HHnd"
      },
      "source": [
        "This phase takes the evaluation results and develops a **strategy for 🚀 deployment**. Some tasks in this phase can be: \n",
        "\n",
        "- 📋 **Summarize the results** (both models and findings). This helps to determine:\n",
        " - Which models can be integrated into our systems \n",
        " - Which findings should be presented\n",
        "- For each deployable model, create a 👣 **step-by-step plan for deployment and integration** with our systems. ✍️ **Note** any **technical details** such as database requirements for model output, latency requirement, etc\n",
        "- For each conclusive finding, create a plan to disseminate this information to strategy makers.\n",
        "- Are there alternative deployment plans for both types of results that are worth mentioning?\n",
        "- Consider **how the deployment** will be 🖥 **monitored**.\n",
        " - How will a model deployed be updated? Will we follow a 🟢🔵 blue-green deployment strategy or 🐦 canary deployment?\n",
        " - How will we decide when the model is no longer applicable? \n",
        "- Identify any deployment 🐛 problems and plan for contingencies. For example, decision-makers may want more information on modeling results and may require that we provide further technical details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_7nreVxHIgR"
      },
      "source": [
        "## 🖥️🔧 Plan monitoring and maintenance <a name=\"7.2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgRZuoHxHJnk"
      },
      "source": [
        "A carefully prepared 🖥 **monitoring and 🔧 maintenance strategy avoids ❌ incorrect usage of data mining results**. In a full-fledged deployment and integration of modeling results, **models may degrade over time** and they need to be 🧐 **evaluated periodically to ensure its effectiveness** and to make continuous ✨ improvements. Some tasks in this phase may include:\n",
        "\n",
        "- Determine **which metrics should be 📏 measured**. For example, 💻 IT metrics (CPU, memory, network usage), latency, model performance (accuracy), etc\n",
        "- Determine **what ℹ information should be logged** for each prediction: inputs, outputs, system action, model metadata, model explanation, etc\n",
        "- Determine the **strategy to 📐 measure and 🖥️ monitor the model's performance**. How can we **detect model’s performance degradation**? Will we perform *ground truth evaluation* or *input drift detection* or both? Give specifics on accuracy **thresholds** or expected changes in data, etc.\n",
        "- What will occur when a model's performance 📉 degrades? \n",
        " - Can we simply retrain the model with fresher data or make slight adjustments? How can we know the new model is better than the actual one running in production? Will we perform **online evaluation** through 🅰🅱 A/B or 🥇🏅 champion-challenger (shadow testing)?\n",
        " - Or will changes be pervasive enough to require a new data mining project?\n",
        "- For each model or finding, which **factors** or influences (such as market value or seasonal variation) need **to be tracked**?\n",
        "- Can this model be used for similar business issues? This is where good ✍️ **documentation** becomes critical for assessing the business purpose 🎯 for each data mining project.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NiSsgAdHLuB"
      },
      "source": [
        "## 📄 Produce final report <a name=\"7.3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbuyiHWkHOs-"
      },
      "source": [
        "📝 Writing a final report ties up loose ends in earlier documentation, and it can also be used **to 📢 communicate our results** to the various 👨‍💼 people with a stake in the results. This report includes all of the previous deliverables and summarizes and **organizes the results**. Depending on the deployment plan, this report may be only a 📋 **summary of the project** and its experiences **or** it may be a final and **comprehensive presentation** of the data mining result(s).\n",
        "\n",
        "It's necessary to **consider the audience of our report**. We may need to create separate reports for each audience if their needs are disparate. In either case, our report should include most of the following ⚫ points:\n",
        "\n",
        "- A thorough **description of** the original **business problem**\n",
        "- The process used to conduct data mining\n",
        "- 💰 **Costs** of the project\n",
        "- Notes on any **deviations** from the original project plan\n",
        "- A 📋 **summary of** data mining **results**, both models and findings\n",
        "- An overview of the proposed plan for deployment\n",
        "- **Recommendations** for further data mining work, including interesting leads discovered during exploration and modeling\n",
        "\n",
        "\n",
        "In addition to the project report, we may also need to present the project findings to a team of sponsors or related departments. If this is the case, we could use much of the same ℹ information in our report but presented from a broader perspective."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45AEOrgqHP1w"
      },
      "source": [
        "## ✨ Review project <a name=\"7.4\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLJTXfslHRLz"
      },
      "source": [
        "This is the final step of the CRISP-DM methodology, and it offers us a chance to formulate our **final impressions and lessons learned** during the data mining process (👎 failures, 👍 successes, potential areas of improvement for use in future projects, etc). This step can include ❓ **interviews with** the significant **project participants**. Questions to consider include the following: \n",
        "\n",
        "- What are your overall **impressions** of the project?\n",
        "- What did you **learn during the process**, both about data mining in general and the data available?\n",
        "- Which parts of the project went well 😀? Where did **difficulties** arise 😖? Was there 📖 information that might have helped ease the confusion?\n",
        "\n",
        "After the data mining results have been 🚀 deployed, we might also ❓ **interview those affected by the results** (such as customers or business partners) to **determine whether the project was worthwhile** and offered the benefits it set out to create."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHUXtW2_4qXd"
      },
      "source": [
        "# 📘 References <a name=\"8\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkagGlwA4raX"
      },
      "source": [
        "- \"The CRISP-DM Model: The New Blueprint for Data Mining\" by Colin Shearer\n",
        "\n",
        "- [CRISP-DM by IBM](https://www.ibm.com/docs/en/spss-modeler/SaaS?topic=guide-introduction-crisp-dm)\n",
        "\n",
        "- [CRISP-DM series by Sngular](https://www.sngular.com/es/data-science-crisp-dm-metodologia/): [Business understanding](https://www.sngular.com/es/crisp-dm-fase-i-comprension-del-negocio/), [Data understanding](https://www.sngular.com/es/crispdm-data-understanding/), [Data preparation](https://www.sngular.com/es/crispdm-data-preparation/), [Modeling](https://www.sngular.com/es/crisp-dm-fase-iv-modeling-modelado/), [Evaluation](https://www.sngular.com/es/crispdm-evaluacion/)."
      ]
    }
  ]
}